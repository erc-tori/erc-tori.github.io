---
layout: default
title: Seminars
permalink: /seminars/
teaser: '/img/tutorial2019.jpg'
---

<a name="levine22"></a>
# July 8, 2022
<table>
  <tr>
    <td width="20%">
      <img width="90%" src="/img/levine2022.jpg">
    </td>

<!--     <td width="10px" /> -->

    <td>
      Joshua Levine --
      University of Arizona<br>
      <a href="https://jalevine.bitbucket.io/" target="new">Web page</a>
<!--       - -->
<!--       <a href="https://twitter.com/JulienTierny" target="new">Twitter</a> -->
      <br>
      <br>
      <i>Neural Representations for Volume Visualization</i>
      <br>
      <br>
      <b>10am, Sorbonne University, Room 2402
<!--      (<a target="new" href="https://zoom.us/j/91588108167?pwd=bzFNUWM3amtraU9aTnMydTR2dUxDZz09">Zoom Link</a>)-->
      </b>
    </td>
  </tr>
</table>

*Abstract:* In this talk, I will describe two projects, both joint work with
collaborators at Vanderbilt University.  The first project studies how
generative neural models can be used to model the process of volume
rendering scalar fields.  We construct a generative adversarial network
that learns the mapping from volume rendering parameters, such as viewpoint
and transfer function, to the rendered image.  In doing so, we can analyze
the volume itself and provide new mechanisms for guiding the user in
transfer function editing and exploring the space of possible images that
can be volume rendered.  Both our training process and applications are
available on the web at [https://github.com/matthewberger/tfgan](https://github.com/matthewberger/tfgan)
In the second part of my talk, I will explore a recent neural modeling
approach for building compressive representations of volume data.  This
approach represents volumetric scalar fields as learned implicit functions
wherein a neural network maps a point in the domain to an output scalar
value. By setting the number of weights of the neural network to be smaller
than the input size, we achieve compressive function approximation.
Combined with carefully quantizing network weights, we show that this
approach yields highly compact representations that outperform
state-of-the-art volume compression approaches. We study the impact of
network design choices on compression performance, highlighting how
conceptually simple network architectures are beneficial for a broad range
of volumes.  Our compression approach is hosted at
[https://github.com/matthewberger/neurcomp](https://github.com/matthewberger/neurcomp)

*Bio:* Joshua A. Levine is an associate professor in the Department of
Computer Science at University of Arizona. Prior to starting at Arizona in
2016, he was an assistant professor at Clemson University from 2012 to
2016, and before that a postdoctoral research associate at the University
of Utah’s SCI Institute from 2009 to 2012. He is a recipient of the 2018
DOE Early Career award. He received his PhD in Computer Science from The
Ohio State University in 2009 after completing BS degrees in Computer
Engineering and Mathematics in 2003 and an MS in Computer Science in 2004
from Case Western Reserve University. His research interests include
visualization, geometric modeling, topological analysis, mesh generation,
vector fields, performance analysis, and computer graphics.

<a name="adams22"></a>
# June 9, 2022
<table>
  <tr>
    <td width="20%">
      <img width="90%" src="/img/adams2022.png">
    </td>

<!--     <td width="10px" /> -->

    <td>
      Henry Adams -- 
      Colorado State University<br>
      <a href="https://www.math.colostate.edu/~adams/" target="new">Web page</a>
<!--       - -->
<!--       <a href="https://twitter.com/JulienTierny" target="new">Twitter</a> -->
      <br>
      <br>
      <i>The unreasonably effective interaction between math and
applications:<br> A case study on persistence images</i>
      <br>
      <br>
      <b>10am, Sorbonne University, Room 2300
      (<a target="new" href="https://zoom.us/j/91588108167?pwd=bzFNUWM3amtraU9aTnMydTR2dUxDZz09">Zoom Link</a>)
      </b>
    </td>
  </tr>
</table>

*Abstract:* Wigner described the unreasonable effectiveness of mathematics in
the natural sciences: ideas from mathematics are unreasonably effective in
advancing applications, and ideas from applications are unreasonably
effective in advancing mathematics. We describe a case study on persistent
images, a stable vector representation of persistent homology. If you
combine topology with data, you get persistent homology. If you combine
persistent homology with machine learning, you might get persistent
landscapes or persistence images or a host of other options. The first
attempt at persistence images were not stable (i.e. continuous), but by
making them stable, their machine learning performance improves, as we will
describe on examples ranging from materials science to biology. This
ping-ponging behavior of injecting ideas from mathematics, then injecting
ideas from applications, etc, leads to robust applied tools and new
mathematical questions. Joint work with Sofya Chepushtanova, Tegan Emerson,
Eric Hanson, Michael Kirby, Francis Motta, Rachel Neville, Chris Peterson,
Patrick Shipman, and Lori Ziegelmeier.

*Bio:* Henry Adams is an Associate Professor of Mathematics at Colorado State
University. His research interests are in computational topology and
geometry, quantitative topology, combinatorial topology, and topological
data analysis. He has applied topology to problems arising in machine
learning, computer vision, minimal sensing, collective motion models, and
chemical energy landscapes. Professor Adams is the Executive Director of
the Applied Algebraic Topology Research Network (AATRN).

<iframe width="100%" height="420"
src="https://www.youtube.com/embed/ptSGKDuEdiI" frameborder="0"
allowfullscreen></iframe>

<a name="summa22"></a>
# May 13, 2022 **[Postponed]**
<table>
  <tr>
    <td width="20%">
      <img width="90%" src="/img/summa2022.jpg">
    </td>

<!--     <td width="10px" /> -->

    <td>
      Brian Summa -- 
      Tulane University<br>
      <a href="https://tulanevisgraphics.bitbucket.io/" target="new">Web page</a>
      <br>
      <br>
      <i>Is Bigger Data Always Better?</i>
      <br>
      <br>
      <b>4pm, Online
      (<a target="new" href="https://zoom.us/j/91588108167?pwd=bzFNUWM3amtraU9aTnMydTR2dUxDZz09">Zoom Link</a>)</b>
    </td>
  </tr>
</table>

*Abstract:* 
Scientific datasets have continually grown in size, driven by the perceived need for higher fidelities to model or measure complex phenomena correctly. This trend comes at a high cost. It requires significant effort and resources to acquire, process, and store this ever-increasing collection of produced data. In this talk, I'll discuss our ongoing efforts to reduce this cost through novel image acquisition, records and analyses of user behavior during exploration, and concise descriptors of data features.

*Bio:* Brian Summa is an Assistant Professor of Computer Science at Tulane University, where he is the head of the visualization and graphics lab. His research interests 
focus on large scale imaging and data analysis.

<a name="aupetit22"></a>
# January 4, 2022
<table>
  <tr>
    <td width="20%">
      <img width="90%" src="/img/aupetit2022.jpg">
    </td>

<!--     <td width="10px" /> -->

    <td>
      Michael Aupetit -- 
      Qatar Computing Research Institute<br>
      <a href="https://about.me/michaelaupetit" target="new">Web page</a>
      -
      <a href="https://twitter.com/MichaelAupetit" target="new">Twitter</a>
      <br>
      <br>
      <i>Visual Analytics, Machine Learning and Topological Models to support 
multidimensional data analysis</i>
      <br>
      <br>
      <b>2pm, Sorbonne University, Room 24-25/405
      (<a target="new" href="https://zoom.us/j/91588108167?pwd=bzFNUWM3amtraU9aTnMydTR2dUxDZz09">Zoom Link</a>)
      </b>
    </td>
  </tr>
</table>

*Abstract:* I will give an overview of my work to support the analyst exploring and 
discovering patterns in multidimensional data.
Topology Data Analysis (TDA) (including clustering) and Multidimensional 
Projection (MDP) techniques are core computational approaches to 
summarize multidimensional (MD) data. But Visualization is a crucial 
component to link the summarized data to the end-user who generates 
knowledge. It relies on finding the most efficient graphical encoding 
and interactions to support the analytical tasks and to account for the 
perceptual and cognitive bottlenecks to fit with the scale of the MD 
data.
I will first present generative models for TDA, to extract a summary of 
the MD data before visualizing it. Then, I will expose MDP techniques 
and their distortions that a new supervised MDP exploits to separate 
classes only if they do not overlap in the MD space. I will switch to 
visualization techniques showing how visual enrichment can solve some of 
the MDP distortions. Then, show how we can start the analytic process 
from scratch with interactive Voronoi treemaps. Finally, I will show how 
to scale the process with perceptual-data-driven visual quality measures 
and discuss future research tracks.

*Bio:* Dr. Michaël Aupetit has worked at the Qatar Computing Research Institute 
since 2014. He is a Senior Scientist with the Social Computing group.
Before joining QCRI, Michaël worked for ten years as a research 
scientist and senior expert in data mining and visual analytics at CEA 
LIST in Paris Saclay. He designed decision support systems to solve 
complex industrial problems in health and security domains.
Michaël initiated and co-organized five international workshops, 
including the first workshop on Topology Learning at NIPS 2007, and 
created and chaired the first Visualization and Computer-Human 
Interaction conference (VisCHI 2019) in the Middle East. He has been a 
PC member of the leading visualization conferences IEEE VIS and Eurovis. 
He also reviewed hundreds of papers for top-tier journals and 
conferences, doing regular reviews for IEEE TVCG, Computer Graphics 
Forum, and Neurocomputing. He contributed more than a hundred 
publications and holds 3 WO , 2 US, and 1 EP patent. He obtained the 
Habilitation for Research Supervision (HDR) in Computer Science from 
Paris 11 Orsay University in 2012,  and the Ph. D degree in Industrial 
Engineering from Grenoble National Polytechnic Institute (INPG) in 2001.
